{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b359f354-6d4c-486c-8a6f-6133b96e5dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Preparation and preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "# Performance evaluation\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, cross_validate, GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, cohen_kappa_score\n",
    "from scipy.stats import ks_2samp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e99013e-c5cf-4027-9b9d-88ede3e14868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"datasets/australian_credit.csv\")\n",
    "df2 = pd.read_csv(\"datasets/GMSC/cs-training.csv\")\n",
    "df3 = pd.read_csv(\"datasets/german_credit.csv\")\n",
    "df4 = pd.read_csv(\"datasets/UCI_Credit_Card.csv\")\n",
    "\n",
    "datasets = [df1, df2, df3, df4]\n",
    "\n",
    "# split each dataset into X and y\n",
    "Xs = []\n",
    "ys = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    Xs.append(dataset.iloc[:, :-1])\n",
    "    ys.append(dataset.iloc[:, -1])\n",
    "\n",
    "ys[2] = ys[2].replace({1: 0, 2: 1})\n",
    "\n",
    "Xs[3].iloc[:, 2] = Xs[3].iloc[:, 2].replace({1: 0, 2: 1})\n",
    "to_drop = Xs[3].columns[[0, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]]\n",
    "Xs[3] = Xs[3].drop(to_drop, axis = 1)\n",
    "\n",
    "Xs[1].loc[65695, \"age\"] = Xs[1][\"age\"].median() # Replace age 0\n",
    "\n",
    "# Fix late payments vars\n",
    "Xs[1].loc[:,'NumberOfTime30-59DaysPastDueNotWorse'] = Xs[1].loc[:,'NumberOfTime30-59DaysPastDueNotWorse'].replace(\n",
    "    {96: Xs[1][\"NumberOfTime30-59DaysPastDueNotWorse\"].median(),\n",
    "        98: Xs[1][\"NumberOfTime30-59DaysPastDueNotWorse\"].median()})\n",
    "Xs[1].loc[:,\"NumberOfTime60-89DaysPastDueNotWorse\"] = Xs[1].loc[:,\"NumberOfTime60-89DaysPastDueNotWorse\"].replace(\n",
    "    {96: Xs[1][\"NumberOfTime60-89DaysPastDueNotWorse\"].median(),\n",
    "     98: Xs[1][\"NumberOfTime60-89DaysPastDueNotWorse\"].median()})\n",
    "Xs[1].loc[:,\"NumberOfTimes90DaysLate\"] = Xs[1].loc[:,\"NumberOfTimes90DaysLate\"].replace(\n",
    "    {96: Xs[1][\"NumberOfTimes90DaysLate\"].median(),\n",
    "     98: Xs[1][\"NumberOfTimes90DaysLate\"].median()})\n",
    "\n",
    "# Looking for categorical and binary variables\n",
    "categorical_columns = [[], [], [], []]\n",
    "binary_columns = [[], [], [], []]\n",
    "for i, X in enumerate(Xs):\n",
    "    for j in range(X.shape[1]):\n",
    "        x = X.iloc[:, j].unique()\n",
    "        if len(x) < 13 and len(x) > 2:\n",
    "            categorical_columns[i].append(j)\n",
    "        elif len(x) == 2:\n",
    "            binary_columns[i].append(j)\n",
    "\n",
    "# Find numeric features\n",
    "not_numeric_columns = [[], [], [], []]\n",
    "for i in range(4):\n",
    "    not_numeric_columns[i] = categorical_columns[i] + binary_columns[i]\n",
    "numeric_columns_index = [[], [], [], []]\n",
    "for i, X in enumerate(Xs):\n",
    "    numeric_columns_index[i] = [x for x in range(\n",
    "        X.shape[1]) if x not in not_numeric_columns[i]]\n",
    "\n",
    "\n",
    "Xs[2].iloc[:, binary_columns[2]] = pd.get_dummies(\n",
    "    Xs[2].iloc[:, binary_columns[2]], drop_first=True, dtype=int).iloc[:, [1, 0, 2, 3]]\n",
    "\n",
    "Xs[2].iloc[:, 17] = Xs[2].iloc[:, 17].replace({1: 0, 2: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ee690c-908a-46f3-be51-e9300940d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the data\n",
    "ct0 = ColumnTransformer([\n",
    "    (\"standardised\", StandardScaler(), ['A2']),\n",
    "    (\"robust\", RobustScaler(), ['A3', 'A5', 'A7', 'A10', 'A13', 'A14']),\n",
    "    (\"categorical\", OneHotEncoder(\n",
    "        handle_unknown='ignore'), ['A4', 'A6', 'A12'])\n",
    "])\n",
    "\n",
    "impute_and_scale = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy='median')),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "ct1 = ColumnTransformer([\n",
    "    (\"impute_and_scale\", impute_and_scale, ['MonthlyIncome', 'NumberOfDependents']),\n",
    "    (\"standardised\", StandardScaler(), [\"age\"]),\n",
    "    (\"robust\", RobustScaler(), ['RevolvingUtilizationOfUnsecuredLines',\n",
    "       'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio',\n",
    "       'NumberOfOpenCreditLinesAndLoans',\n",
    "       'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfTimes90DaysLate'])\n",
    "])\n",
    "\n",
    "to_dense_transformer = FunctionTransformer(lambda x: x.toarray(), accept_sparse=True) # Convert sparse matrix to dense\n",
    "ct2 = ColumnTransformer([\n",
    "    (\"standardised\", StandardScaler(), [\"Age\"]),\n",
    "    (\"robust\", RobustScaler(), ['Duration', 'Credit_amount']),\n",
    "    (\"categorical\", OneHotEncoder(\n",
    "        handle_unknown='ignore'), categorical_columns[2])\n",
    "])\n",
    "\n",
    "ct3 = ColumnTransformer([\n",
    "    (\"standardised\", StandardScaler(), [\"AGE\"]),\n",
    "    (\"robust\", RobustScaler(), ['LIMIT_BAL', 'BILL_AMT1', 'PAY_AMT1',\n",
    "                                'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5',\n",
    "                                'PAY_AMT6']),\n",
    "    (\"categorical\", OneHotEncoder(\n",
    "        handle_unknown='ignore'), ['EDUCATION', 'MARRIAGE', 'PAY_0'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145f3b65-8bb1-4ada-9cae-fe9a5899761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "skf_outer = StratifiedKFold(n_splits=10, shuffle=True, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5f3bc1-e39d-475e-bdf9-e3d4201139d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM pipelines\n",
    "Pipeline0_svm = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct0),\n",
    "        (\"classifier\", SVC(C=10, max_iter=10000, probability=True, random_state=7)),\n",
    "    ]\n",
    ")\n",
    "Pipeline1_svm = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct1),\n",
    "        (\"classifier\", LinearSVC(C=1, max_iter=10000, random_state=7)),\n",
    "    ]\n",
    ")\n",
    "Pipeline2_svm = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct2),\n",
    "        (\"classifier\", SVC(C=10, max_iter=10000, probability=True, random_state=7)),\n",
    "    ]\n",
    ")\n",
    "Pipeline3_svm = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct3),\n",
    "        (\"classifier\", LinearSVC(C=0.1, max_iter=10000, random_state=7)),\n",
    "    ]\n",
    ")\n",
    "# dt pipelines\n",
    "Pipeline0_dt = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct0),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            DecisionTreeClassifier(max_depth=10, max_features=\"sqrt\", min_samples_leaf=6, random_state=7),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "Pipeline1_dt = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct1),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            DecisionTreeClassifier(max_features=\"sqrt\", min_samples_leaf=4, random_state=7),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "Pipeline2_dt = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct2),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            DecisionTreeClassifier(max_depth=5, max_features=\"sqrt\", min_samples_leaf=4, random_state=7),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "Pipeline3_dt = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct3),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            DecisionTreeClassifier(max_depth=10, max_features=\"sqrt\", random_state=7),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Knn pipelines\n",
    "Pipeline0_knn = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct0),\n",
    "        (\"classifier\", KNeighborsClassifier(n_neighbors=15, weights=\"distance\")),\n",
    "    ]\n",
    ")\n",
    "Pipeline1_knn = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct1),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            KNeighborsClassifier(leaf_size=40, n_neighbors=3, weights=\"distance\"),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "Pipeline2_knn = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct2),\n",
    "        (\"classifier\", KNeighborsClassifier(weights=\"distance\")),\n",
    "    ]\n",
    ")\n",
    "Pipeline3_knn = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct3),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            KNeighborsClassifier(leaf_size=40, n_neighbors=10, weights=\"distance\"),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# RF pipelines\n",
    "Pipeline0_rf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct0),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            RandomForestClassifier(max_depth=20, max_features=\"log2\", min_samples_split=10, random_state=7),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "Pipeline1_rf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct1),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            RandomForestClassifier(max_depth=20, max_features=\"log2\", min_samples_split=5, random_state=7),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "Pipeline2_rf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct2),\n",
    "        (\"classifier\", RandomForestClassifier(random_state=7)),\n",
    "    ]\n",
    ")\n",
    "Pipeline3_rf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct3),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            RandomForestClassifier(max_depth=30, min_samples_split=5, random_state=7),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# LR pipelines\n",
    "Pipeline0_lr = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct0),\n",
    "        (\"classifier\", LogisticRegression(C=1, solver=\"liblinear\")),\n",
    "    ]\n",
    ")\n",
    "Pipeline1_lr = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct1),\n",
    "        (\"classifier\", LogisticRegression(C=1, solver=\"newton-cg\")),\n",
    "    ]\n",
    ")\n",
    "Pipeline2_lr = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct2),\n",
    "        (\"classifier\", LogisticRegression(C=1, solver=\"newton-cg\")),\n",
    "    ]\n",
    ")\n",
    "Pipeline3_lr = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct3),\n",
    "        (\"classifier\", LogisticRegression(C=1, solver=\"newton-cg\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# MLP pipelines\n",
    "Pipeline0_mlp = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct0),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            MLPClassifier(\n",
    "                early_stopping=True,\n",
    "                hidden_layer_sizes=(200, 100),\n",
    "                max_iter=2000,\n",
    "                random_state=7,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "Pipeline1_mlp = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct1),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            MLPClassifier(\n",
    "                activation=\"logistic\",\n",
    "                early_stopping=True,\n",
    "                hidden_layer_sizes=(200,),\n",
    "                max_iter=2000,\n",
    "                random_state=7,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "Pipeline2_mlp = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct2),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            MLPClassifier(\n",
    "                activation=\"tanh\",\n",
    "                hidden_layer_sizes=(200, 100),\n",
    "                max_iter=2000,\n",
    "                random_state=7,\n",
    "                solver=\"lbfgs\",\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "Pipeline3_mlp = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct3),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            MLPClassifier(early_stopping=True, max_iter=2000, random_state=7),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# lda pipelines\n",
    "Pipeline0_lda = Pipeline(steps=[(\"preprocessor\", ct0), (\"classifier\", LinearDiscriminantAnalysis())])\n",
    "Pipeline1_lda = Pipeline(steps=[(\"preprocessor\", ct1), (\"classifier\", LinearDiscriminantAnalysis())])\n",
    "Pipeline2_lda = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", ct2),\n",
    "        (\"to_dense\", to_dense_transformer),\n",
    "        (\"classifier\", LinearDiscriminantAnalysis()),\n",
    "    ]\n",
    ")\n",
    "Pipeline3_lda = Pipeline(steps=[(\"preprocessor\", ct3), (\"classifier\", LinearDiscriminantAnalysis())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d45f0801-9cf1-47d9-b914-008034ffdd3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Final training and tests\n",
    "\n",
    "def ks_statistic(y_true, y_pred_prob):\n",
    "    y_true = y_true.astype(int)\n",
    "    return ks_2samp(y_pred_prob[y_true == 1], y_pred_prob[y_true == 0]).statistic\n",
    "\n",
    "\n",
    "ks_scorer = make_scorer(ks_statistic, response_method='predict_proba')\n",
    "\n",
    "\n",
    "metrics = {'accuracy': 'accuracy', 'precision': 'precision',\n",
    "           'recall': 'recall', 'ks': ks_scorer, \"kappa\": make_scorer(cohen_kappa_score), 'roc_auc': 'roc_auc'}\n",
    "\n",
    "def cv_pipelines(pipelines, X, y, metrics, cv):\n",
    "    results = []\n",
    "    result_means = []\n",
    "    for pipeline in pipelines:\n",
    "        result = cross_validate(\n",
    "            pipeline, X, y, scoring=metrics, cv=cv, return_train_score=True, n_jobs=-1)\n",
    "        results.append(pd.DataFrame(result))\n",
    "        result_means.append(np.mean(pd.DataFrame(result), axis=0))\n",
    "    return (results, result_means)\n",
    "    \n",
    "pipelines = {\n",
    "0 : [Pipeline0_lr, Pipeline0_rf, Pipeline0_lda, Pipeline0_knn,\n",
    "                Pipeline0_mlp, Pipeline0_dt, Pipeline0_svm],\n",
    "1 : [Pipeline1_lr, Pipeline1_rf, Pipeline1_lda, Pipeline1_knn,\n",
    "                  Pipeline1_mlp, Pipeline1_dt],\n",
    "2 : [Pipeline2_lr, Pipeline2_rf, Pipeline2_lda, Pipeline2_knn,\n",
    "                           Pipeline2_mlp, Pipeline2_dt, Pipeline2_svm],\n",
    "3 : [Pipeline3_lr, Pipeline3_rf, Pipeline3_lda, Pipeline3_knn,\n",
    "                             Pipeline3_mlp, Pipeline3_dt]\n",
    "}\n",
    "\n",
    "result0, result_mean0 = cv_pipelines(pipelines[0], Xs[0], ys[0], metrics, cv=skf_outer)\n",
    "result1, result_mean1 = cv_pipelines(pipelines[1], Xs[1], ys[1], metrics, cv=skf_outer)\n",
    "result2, result_mean2 = cv_pipelines(pipelines[2], Xs[2], ys[2], metrics, cv=skf_outer)\n",
    "result3, result_mean3 = cv_pipelines(pipelines[3], Xs[3], ys[3], metrics, cv=skf_outer)\n",
    "\n",
    "pd.concat([pd.DataFrame(result_mean0),\n",
    "           pd.DataFrame(result_mean1),\n",
    "           pd.DataFrame(result_mean2),\n",
    "           pd.DataFrame(result_mean3)]).to_csv('consolidated_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3064bcab-0a54-4a92-96e7-b85c81c0c966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ks_statistic(y_true, y_pred_prob):\n",
    "    y_true = y_true.astype(int)\n",
    "    return ks_2samp(y_pred_prob[y_true == 1], y_pred_prob[y_true == 0]).statistic\n",
    "\n",
    "\n",
    "ks_scorer = make_scorer(ks_statistic, response_method='decision_function')\n",
    "\n",
    "metrics = {'accuracy': 'accuracy', 'precision': 'precision',\n",
    "           'recall': 'recall', 'ks': ks_scorer, \"kappa\": make_scorer(cohen_kappa_score), 'roc_auc': 'roc_auc'}\n",
    "\n",
    "svm1_res = cross_validate(Pipeline1_svm, Xs[1], ys[1], scoring=metrics, cv=skf_outer, return_train_score=True, n_jobs=-1)\n",
    "svm3_res = cross_validate(Pipeline3_svm, Xs[3], ys[3], scoring=metrics, cv=skf_outer, return_train_score=True, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67c74d63-91cc-4c62-983d-a56061431465",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(svm1_res).mean(axis=0), pd.DataFrame(svm3_res).mean(axis=0)]).to_excel(\"svm.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa567928-0c28-450c-a6b6-30b6dbb87b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The X2 statistic is 0.48 with a p value = 0.92, we fail to reject H0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import friedmanchisquare\n",
    "ac_ranks = [3.55,1.45,5.55,5.45,2.7,6.7,2.6]\n",
    "gmsc_ranks = [5.4,2.4,4.2,4.85,3.1,2.95,3.85]\n",
    "gc_ranks = [2.7,2.8,2.9,5.45,4.35,7,2.8]\n",
    "tc_ranks = [3.2,2.05,3.6,6.7,3.25,6.3,2.9]\n",
    "\n",
    "res = friedmanchisquare(ac_ranks, gmsc_ranks, gc_ranks, tc_ranks)\n",
    "if res.pvalue < 0.05:\n",
    "    print(f\"The X2 statistic is {res.statistic:.2f} with a p value = {res.pvalue:.2f}, we reject H0\")\n",
    "else:\n",
    "    print(f\"The X2 statistic is {res.statistic:.2f} with a p value = {res.pvalue:.2f}, we fail to reject H0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
